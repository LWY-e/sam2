# 파인튜닝 방법론

## 문제점
  - 기존 어노테이션시 큰 덩어리를 여러 객체로 쪼개서 진행
  - 학습된 모델에서 큰 덩어리를 인식하지 못하거나
  - 큰 덩어리를 작은 덩어리로 쪼개서 인식하는 문제 발생

## 해결 방법

### 1. 기존 파인 튜닝 모델에 부족한 부분을 추가로 학습

- 파인튜닝된 모델에 큰 덩어리를 어노테이션 한 파일들을 추가 학습
  
- 기존 데이터(큰 덩어리를 쪼개서 인식시킨)와의 혼선 의문 발생

### 예상 결과
- 어떤 경우에는 하나로 탐지하고, 어떤 경우에는 쪼개서 탐지하는 등 예측 불가능한 결과
  
- 하나로 탐지하는 것과 쪼개서 탐지하는 것 모두를 시도하며 성능 불안정
  
- 추가 학습 데이터의 양이나 학습 방법에 따라 기존에 잘 탐지하던 객체나 작은 객체에 대한 성능 저하

### 참고 자료

- 기존 데이터에 기준을 여러 가지로 학습시킬 시 문제점이 있는지에 대한 자료 탐색
  
1. 파국적 망각 및 연속 학습
   - "Overcoming catastrophic forgetting in neural networks"
   - 신경망이 새로운 작업을 학습할 때 이전 작업을 잊어버리는 파국적 망각 현상을 다룸
   
2. 데이터 품질 및 어노테이션 일관성 영향 관련
   - TorchVision Object Detection Finetuning Tutorial
   - 모델이 데이터를 올바르게 학습하기 위해서는 데이터셋 전체에 걸쳐 어노테이션 형식이 통일되고 정확해야한다는 전제가 깔림
     
## 2. 기본 모델에 새로운 데이터셋 학습

- 기존 데이터의 큰 객체 어노테이션 수정 + 새 데이터 추가후 처음부터 다시 학습 또는 파인튜닝

### 예상 결과
- 큰 객체에 대한 어노테이션 정책이 전체 데이터셋에 걸쳐 일관 적용
  
- 처음부터 큰 객체에 대해 하나로 탐지하는 일관된 지시로 안정적으로 학습 가능

- 처음부터 학습을 진행해야 하기에 시간이 추가 학습 과정보다 오래 걸림

### 3. 결론
- 모델이 큰 객체를 하나의 덩어리로 인식시키기 위해서는 새로운 데이터셋으로
  1. 기본 모델에 처음부터 학습
  2. 파인튜닝 모델의 초기값만 사용후 낮은 학습률로 파인튜닝
하는 방식으로 진행해야 함
  
